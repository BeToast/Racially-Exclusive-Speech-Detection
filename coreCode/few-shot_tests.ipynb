{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blake/miniconda3/envs/tf/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-01 18:24:32.289116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 18:24:34.979590: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.5/lib64:/usr/local/cuda-11.5/lib64\n",
      "2023-02-01 18:24:34.979730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.5/lib64:/usr/local/cuda-11.5/lib64\n",
      "2023-02-01 18:24:34.979741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/home/blake/miniconda3/envs/tf/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"/home/blake/miniconda3/envs/tf/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m test_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mDataset(pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_pandas(eval_dataframe))\n\u001b[1;32m     14\u001b[0m \u001b[39m# Load a SetFit model from Hub\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[39m=\u001b[39m SetFitModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mfacebook/bart-large-mnli\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Create trainer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m trainer \u001b[39m=\u001b[39m SetFitTrainer(\n\u001b[1;32m     19\u001b[0m   model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m   train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m   column_mapping\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m} \u001b[39m# Map dataset columns to text/label expected by trainer\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m test_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mDataset(pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_pandas(eval_dataframe))\n\u001b[1;32m     14\u001b[0m \u001b[39m# Load a SetFit model from Hub\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[39m=\u001b[39m SetFitModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mfacebook/bart-large-mnli\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Create trainer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m trainer \u001b[39m=\u001b[39m SetFitTrainer(\n\u001b[1;32m     19\u001b[0m   model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m   train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m   column_mapping\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m} \u001b[39m# Map dataset columns to text/label expected by trainer\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:662\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1087\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1078\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1973\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   1975\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[0;32m-> 1976\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   1978\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   1981\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_mpl_hook()\n\u001b[1;32m   2010\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2011\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2015\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import pyarrow as pa\n",
    "\n",
    "# train pairs 4\n",
    "train_dataframe = pd.read_csv(\"../data_ready/few_shot/train_pairs_random_4.csv\").sample(frac=1)\n",
    "eval_dataframe = pd.read_csv(\"../data_ready/unused_pairs_for_test_data.csv\").sample(frac=1)\n",
    "\n",
    "train_dataset = datasets.Dataset(pa.Table.from_pandas(train_dataframe))\n",
    "test_dataset = datasets.Dataset(pa.Table.from_pandas(eval_dataframe))\n",
    "\n",
    "# Load a SetFit model from Hub\n",
    "model = SetFitModel.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "  model=model,\n",
    "  train_dataset=train_dataset,\n",
    "  eval_dataset=test_dataset,\n",
    "  loss_class=CosineSimilarityLoss,\n",
    "  metric=\"accuracy\",\n",
    "  batch_size=16,\n",
    "  num_iterations=20, # The number of text pairs to generate for contrastive learning\n",
    "  num_epochs=1, # The number of epochs to use for contrastive learning\n",
    "  column_mapping={\"text\": \"text\", \"class\": \"label\"} # Map dataset columns to text/label expected by trainer\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "################ hugging face hub?? ##################\n",
    "# Push model to the Hub\n",
    "# trainer.push_to_hub(\"my-awesome-setfit-model\")\n",
    "\n",
    "# Download from Hub and run inference\n",
    "# model = SetFitModel.from_pretrained(\"lewtun/my-awesome-setfit-model\")\n",
    "###############################################\n",
    "\n",
    "# Run inference\n",
    "# preds = model([\"i loved the spiderman movie!\", \"pineapple on pizza is the worst ðŸ¤®\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a20bf4446eb962a62a523ed10fefb4852bfc518dc6434bbccd861f07f3b19b23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
