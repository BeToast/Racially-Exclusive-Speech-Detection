{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create results files for each fold of every for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from os import walk, makedirs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "predictions_dir = '../predictions'\n",
    "# k_folds_dirs = next(walk(predictions_dir))[1]\n",
    "pretrained_dirnames =['bert-base-multilingual-cased-sentiment-multilingual',\n",
    "                      'dehatebert-mono-french',\n",
    "                      'french_xlm_xnli',\n",
    "                      'xlm-roberta-base-sentiment-multilingual']\n",
    "\n",
    "result_cols=[\"model\", \"traindata\", \"accuracy\", \"std_accuracy\", \"precision\", \"std_precision\", \"recall\", \"std_recall\", \"f1\", \"std_f1\"]\n",
    "dfs ={'bert-base-multilingual-cased-sentiment-multilingual':pd.DataFrame(columns=result_cols),\n",
    "      'dehatebert-mono-french':pd.DataFrame(columns=result_cols),\n",
    "      'french_xlm_xnli':pd.DataFrame(columns=result_cols),\n",
    "      'xlm-roberta-base-sentiment-multilingual':pd.DataFrame(columns=result_cols)}\n",
    "\n",
    "for pretrained in pretrained_dirnames:\n",
    "  df = dfs.get(pretrained)\n",
    "  result_files = next(walk(f\"{predictions_dir}/k_is_0/{pretrained}/\"))[2]\n",
    "  for file in result_files: # 'text', 'class', 'predicted'\n",
    "    prec = list()\n",
    "    recall = list()\n",
    "    f1 = list()\n",
    "    accuracy = list()\n",
    "    for k in range(0,3):\n",
    "      results = pd.read_csv(f\"{predictions_dir}/k_is_{k}/{pretrained}/{file}\").sample(frac=1)\n",
    "      prec_curr, recall_curr, f1_curr, _ = precision_recall_fscore_support(results[\"class\"], results[\"predicted\"], average='macro')\n",
    "      accuracy_curr = accuracy_score(results[\"class\"], results[\"predicted\"])\n",
    "      prec.append(prec_curr)\n",
    "      recall.append(recall_curr)\n",
    "      f1.append(f1_curr)\n",
    "      accuracy.append(accuracy_curr)\n",
    "    \n",
    "    # add results to dict\n",
    "    df.loc[len(df.index)] = [pretrained, file,\n",
    "                            np.mean(accuracy), stdev(accuracy),\n",
    "                            np.mean(prec), stdev(prec),\n",
    "                            np.mean(recall), stdev(recall),\n",
    "                            np.mean(f1), stdev(f1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir=\"../results\"\n",
    "for pretrained in pretrained_dirnames:\n",
    "  dfs[pretrained].to_csv(f\"{results_dir}/{pretrained}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a087ff6df60b7b11c8f40c254358573ffeaae9884c78b2d4011057590ac9004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
