{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "def get_text_class_buffer(indexes, eng_inc, eng_exc, frn_inc, frn_exc):\n",
    "  text_buffer = []\n",
    "  class_buffer = []\n",
    "  for i in indexes:\n",
    "    text_buffer.append(eng_inc[i])\n",
    "    class_buffer.append(1)\n",
    "    text_buffer.append(eng_exc[i])\n",
    "    class_buffer.append(0)\n",
    "    text_buffer.append(frn_inc[i])\n",
    "    class_buffer.append(1)\n",
    "    text_buffer.append(frn_exc[i])\n",
    "    class_buffer.append(0)\n",
    "  return text_buffer, class_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_inc=[i.strip() for i in list(open(\"english_inclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "eng_exc=[i.strip() for i in list(open(\"english_exclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "frn_inc=[i.strip() for i in list(open(\"french_inclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "frn_exc=[i.strip() for i in list(open(\"french_exclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "\n",
    "if len(eng_inc) != len(eng_exc):\n",
    "  raise Exception(\"uneven english pairs\")\n",
    "\n",
    "if len(frn_inc) != len(frn_exc):\n",
    "  raise Exception(\"uneven french pairs\")\n",
    "\n",
    "if len(eng_inc) != len(frn_inc):\n",
    "  raise Exception(\"amounts across french and english datasets\")\n",
    "\n",
    "num_kfolds = 3 #amount of folds to split data into. 3 is best and divides equally.\n",
    "all_indexes_static = set(range(len(eng_exc)))\n",
    "unused_indexes = set(range(len(eng_exc))) # keep track of unused indexes\n",
    "indexes_per_fold = int(len(eng_exc)/num_kfolds)\n",
    "\n",
    "text_buffer = []\n",
    "class_buffer = []\n",
    "#create data for number of folds\n",
    "for fold in range(num_kfolds):\n",
    "  # get indexes for current fold train\n",
    "  unused_fold_indexes=set(rd.sample(unused_indexes, indexes_per_fold))\n",
    "  unused_indexes-=unused_fold_indexes\n",
    "  # store current fold test data\n",
    "  test_indexes = all_indexes_static-unused_fold_indexes\n",
    "  df=pd.DataFrame()\n",
    "  df[\"text\"], df[\"class\"] = get_text_class_buffer(test_indexes, eng_inc, eng_exc, frn_inc, frn_exc)\n",
    "  df.to_csv(f\"../data_ready/k_is_{fold}/test.csv\", index=False)\n",
    "\n",
    "  # local globals for this while loop.\n",
    "  df_text=[]\n",
    "  df_class=[]\n",
    "  sample_size = 2\n",
    "  previous_size = 0\n",
    "  while sample_size < indexes_per_fold:\n",
    "    df=pd.DataFrame()\n",
    "    curr_indexes=set(rd.sample(unused_fold_indexes, sample_size-previous_size))\n",
    "    unused_fold_indexes-=curr_indexes\n",
    "    \n",
    "    # get for sentences for every index.\n",
    "    text_buffer, class_buffer = get_text_class_buffer(curr_indexes, eng_inc, eng_exc, frn_inc, frn_exc)\n",
    "    # add buffer to df\n",
    "    df_text.extend(text_buffer)\n",
    "    df_class.extend(class_buffer)\n",
    "    df[\"text\"]=df_text\n",
    "    df[\"class\"]=df_class\n",
    "\n",
    "    # output to csv\n",
    "    df.to_csv(f\"../data_ready/k_is_{fold}/train{sample_size}.csv\", index=False)\n",
    "    sample_size*=2\n",
    "    previous_size+=len(curr_indexes)\n",
    "\n",
    "  # clear for next fold\n",
    "  text_buffer.clear()\n",
    "  class_buffer.clear()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text_buffer.clear()\n",
    "# train_class_buffer.clear()\n",
    "\n",
    "# four_ran_pairs=ran.sample(single_example_range, 4)\n",
    "# print(four_ran_pairs)\n",
    "\n",
    "# for i in four_ran_pairs:\n",
    "#   if on_english:\n",
    "#     train_text_buffer.append(eng_inc[i])\n",
    "#     train_class_buffer.append(1)\n",
    "#     train_text_buffer.append(eng_exc[i])\n",
    "#     train_class_buffer.append(0)\n",
    "#   else:\n",
    "#     train_text_buffer.append(frn_inc[i])\n",
    "#     train_class_buffer.append(1)\n",
    "#     train_text_buffer.append(frn_exc[i])\n",
    "#     train_class_buffer.append(0)\n",
    "\n",
    "#   on_english=not on_english\n",
    "\n",
    "# train_pairs_random_4[\"text\"]=train_text_buffer\n",
    "# train_pairs_random_4[\"class\"]=train_class_buffer\n",
    "\n",
    "# used_index += four_ran_pairs\n",
    "# train_pairs_random_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pairs_random_4.to_csv(\"../../data_ready/few_shot/train_pairs_random_4.csv\", index=False)\n",
    "# train_pairs_random_8.to_csv(\"../../data_ready/few_shot/train_pairs_random_8.csv\", index=False)\n",
    "# train_unrelated_random_8.to_csv(\"../../data_ready/few_shot/train_unrelated_random_8.csv\", index=False)\n",
    "# train_unrelated_random_16.to_csv(\"../../data_ready/few_shot/train_unrelated_random_16.csv\", index=False)\n",
    "# test_set.to_csv(\"../../data_ready/unused_pairs_for_test_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a20bf4446eb962a62a523ed10fefb4852bfc518dc6434bbccd861f07f3b19b23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
