{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "def get_text_class_buffer(indexes, eng_inc, eng_exc, frn_inc, frn_exc):\n",
    "  text_buffer = []\n",
    "  lang_buffer = []\n",
    "  class_buffer = []\n",
    "  for i in indexes:\n",
    "    text_buffer.append(eng_inc[i])\n",
    "    class_buffer.append(1)\n",
    "    lang_buffer.append(\"en\")\n",
    "    text_buffer.append(eng_exc[i])\n",
    "    class_buffer.append(0)\n",
    "    lang_buffer.append(\"en\")\n",
    "    text_buffer.append(frn_inc[i])\n",
    "    class_buffer.append(1)\n",
    "    lang_buffer.append(\"fr\")\n",
    "    text_buffer.append(frn_exc[i])\n",
    "    class_buffer.append(0)\n",
    "    lang_buffer.append(\"fr\")\n",
    "  return text_buffer, lang_buffer, class_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45004/1653536316.py:25: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  unused_fold_indexes=set(rd.sample(unused_indexes, indexes_per_fold))\n",
      "/tmp/ipykernel_45004/1653536316.py:40: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  curr_indexes=set(rd.sample(unused_fold_indexes, sample_size-previous_size))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m unused_fold_indexes\u001b[39m-\u001b[39m\u001b[39m=\u001b[39mcurr_indexes\n\u001b[1;32m     43\u001b[0m \u001b[39m# get for sentences for every index.\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m text_buffer, class_buffer \u001b[39m=\u001b[39m get_text_class_buffer(curr_indexes, eng_inc, eng_exc, frn_inc, frn_exc)\n\u001b[1;32m     45\u001b[0m \u001b[39m# add buffer to df\u001b[39;00m\n\u001b[1;32m     46\u001b[0m df_text\u001b[39m.\u001b[39mextend(text_buffer)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "eng_inc=[i.strip() for i in list(open(\"english_inclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "eng_exc=[i.strip() for i in list(open(\"english_exclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "frn_inc=[i.strip() for i in list(open(\"french_inclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "frn_exc=[i.strip() for i in list(open(\"french_exclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "\n",
    "if len(eng_inc) != len(eng_exc):\n",
    "  raise Exception(\"uneven english pairs\")\n",
    "\n",
    "if len(frn_inc) != len(frn_exc):\n",
    "  raise Exception(\"uneven french pairs\")\n",
    "\n",
    "if len(eng_inc) != len(frn_inc):\n",
    "  raise Exception(\"amounts across french and english datasets\")\n",
    "\n",
    "num_kfolds = 3 #amount of folds to split data into. 3 is best and divides equally.\n",
    "all_indexes_static = set(range(len(eng_exc)))\n",
    "unused_indexes = set(range(len(eng_exc))) # keep track of unused indexes\n",
    "indexes_per_fold = int(len(eng_exc)/num_kfolds)\n",
    "\n",
    "text_buffer = []\n",
    "class_buffer = []\n",
    "#create data for number of folds\n",
    "for fold in range(num_kfolds):\n",
    "  # get indexes for current fold train\n",
    "  unused_fold_indexes=set(rd.sample(unused_indexes, indexes_per_fold))\n",
    "  unused_indexes-=unused_fold_indexes\n",
    "  # store current fold test data\n",
    "  test_indexes = all_indexes_static-unused_fold_indexes\n",
    "  df=pd.DataFrame()\n",
    "  df[\"text\"], df[\"lang\"], df[\"class\"] = get_text_class_buffer(test_indexes, eng_inc, eng_exc, frn_inc, frn_exc)\n",
    "  df.to_csv(f\"../data_ready/k_is_{fold}/test.csv\", index=False)\n",
    "\n",
    "  # local globals for this while loop.\n",
    "  df_text=[]\n",
    "  df_lang=[]\n",
    "  df_class=[]\n",
    "  sample_size = 2\n",
    "  previous_size = 0\n",
    "  while sample_size <= indexes_per_fold:\n",
    "    df=pd.DataFrame()\n",
    "    curr_indexes=set(rd.sample(unused_fold_indexes, sample_size-previous_size))\n",
    "    unused_fold_indexes-=curr_indexes\n",
    "    \n",
    "    # get for sentences for every index.\n",
    "    text_buffer, lang_buffer, class_buffer = get_text_class_buffer(curr_indexes, eng_inc, eng_exc, frn_inc, frn_exc)\n",
    "    # add buffer to df\n",
    "    df_text.extend(text_buffer)\n",
    "    df_lang.extend(lang_buffer)\n",
    "    df_class.extend(class_buffer)\n",
    "    df[\"text\"]=df_text\n",
    "    df[\"lang\"]=df_lang\n",
    "    df[\"class\"]=df_class\n",
    "\n",
    "    # output to csv\n",
    "    df.to_csv(f\"../data_ready/k_is_{fold}/train{sample_size}.csv\", index=False)\n",
    "    if sample_size < 16:\n",
    "      sample_size*=2\n",
    "    else:\n",
    "      sample_size+=6\n",
    "\n",
    "    previous_size+=len(curr_indexes)\n",
    "\n",
    "  # clear for next fold\n",
    "  text_buffer.clear()\n",
    "  class_buffer.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
