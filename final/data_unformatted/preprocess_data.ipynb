{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "#### THIS IS A SAFTEY SO WE DO NOT OVERWRITE CURR SPLIT ACCIDENTALLY #####\n",
    "TOCSV_TOGGLE = False\n",
    "\n",
    "\n",
    "def get_text_class_buffer(indexes, eng_inc, eng_exc, frn_inc, frn_exc):\n",
    "  text_buffer = []\n",
    "  lang_buffer = []\n",
    "  class_buffer = []\n",
    "  for i in indexes:\n",
    "    text_buffer.append(eng_inc[i])\n",
    "    class_buffer.append(1)\n",
    "    lang_buffer.append(\"en\")\n",
    "    text_buffer.append(eng_exc[i])\n",
    "    class_buffer.append(0)\n",
    "    lang_buffer.append(\"en\")\n",
    "    text_buffer.append(frn_inc[i])\n",
    "    class_buffer.append(1)\n",
    "    lang_buffer.append(\"fr\")\n",
    "    text_buffer.append(frn_exc[i])\n",
    "    class_buffer.append(0)\n",
    "    lang_buffer.append(\"fr\")\n",
    "  return text_buffer, lang_buffer, class_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_inc=[i.strip() for i in list(open(\"english_inclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "eng_exc=[i.strip() for i in list(open(\"english_exclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "frn_inc=[i.strip() for i in list(open(\"french_inclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "frn_exc=[i.strip() for i in list(open(\"french_exclusive_pure.txt\", encoding='utf-8-sig').read().splitlines())]\n",
    "\n",
    "if len(eng_inc) != len(eng_exc):\n",
    "  raise Exception(\"uneven english pairs\")\n",
    "\n",
    "if len(frn_inc) != len(frn_exc):\n",
    "  raise Exception(\"uneven french pairs\")\n",
    "\n",
    "if len(eng_inc) != len(frn_inc):\n",
    "  raise Exception(\"amounts across french and english datasets\")\n",
    "\n",
    "num_kfolds = 3 #amount of folds to split data into. 3 is best and divides equally.\n",
    "all_indexes_static = set(range(len(eng_exc)))\n",
    "unused_indexes = set(range(len(eng_exc))) # keep track of unused indexes\n",
    "indexes_per_fold = int(len(eng_exc)/num_kfolds)\n",
    "\n",
    "text_buffer = []\n",
    "class_buffer = []\n",
    "\n",
    "#get all data to CSV\n",
    "df=pd.DataFrame()\n",
    "df[\"text\"], df[\"lang\"], df[\"class\"] = get_text_class_buffer(all_indexes_static, eng_inc, eng_exc, frn_inc, frn_exc)\n",
    "if TOCSV_TOGGLE: df.to_csv(f\"../data_ready/all_data.csv\", index=False)\n",
    "\n",
    "#create data for number of folds\n",
    "for fold in range(num_kfolds):\n",
    "  # get indexes for current fold train\n",
    "  unused_fold_indexes=set(rd.sample(unused_indexes, indexes_per_fold))\n",
    "  unused_indexes-=unused_fold_indexes\n",
    "  # store current fold test data\n",
    "  test_indexes = all_indexes_static-unused_fold_indexes\n",
    "  df=pd.DataFrame()\n",
    "  df[\"text\"], df[\"lang\"], df[\"class\"] = get_text_class_buffer(test_indexes, eng_inc, eng_exc, frn_inc, frn_exc)\n",
    "  if TOCSV_TOGGLE: df.to_csv(f\"../data_ready/k_is_{fold}/test.csv\", index=False)\n",
    "\n",
    "  # local globals for this while loop.\n",
    "  df_text=[]\n",
    "  df_lang=[]\n",
    "  df_class=[]\n",
    "  sample_size = 2\n",
    "  previous_size = 0\n",
    "  while sample_size <= indexes_per_fold:\n",
    "    df=pd.DataFrame()\n",
    "    curr_indexes=set(rd.sample(unused_fold_indexes, sample_size-previous_size))\n",
    "    unused_fold_indexes-=curr_indexes\n",
    "    \n",
    "    # get for sentences for every index.\n",
    "    text_buffer, lang_buffer, class_buffer = get_text_class_buffer(curr_indexes, eng_inc, eng_exc, frn_inc, frn_exc)\n",
    "    # add buffer to df\n",
    "    df_text.extend(text_buffer)\n",
    "    df_lang.extend(lang_buffer)\n",
    "    df_class.extend(class_buffer)\n",
    "    df[\"text\"]=df_text\n",
    "    df[\"lang\"]=df_lang\n",
    "    df[\"class\"]=df_class\n",
    "\n",
    "    # output to csv\n",
    "    if TOCSV_TOGGLE: df.to_csv(f\"../data_ready/k_is_{fold}/train{sample_size}.csv\", index=False)\n",
    "    if sample_size < 16:\n",
    "      sample_size*=2\n",
    "    else:\n",
    "      sample_size+=6\n",
    "\n",
    "    previous_size+=len(curr_indexes)\n",
    "\n",
    "  # clear for next fold\n",
    "  text_buffer.clear()\n",
    "  class_buffer.clear()\n",
    "\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
