{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-03-20 14:16:00.013800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-20 14:16:02.098552: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.5/lib64:/usr/local/cuda-11.5/lib64\n","2023-03-20 14:16:02.098714: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.5/lib64:/usr/local/cuda-11.5/lib64\n","2023-03-20 14:16:02.098725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["from os import walk, makedirs\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import SGDClassifier\n","from sentence_transformers import SentenceTransformer"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### function to read all data in from data_ready/  \n","data is already split in to k folds"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def read_data_for_fold(k: int) -> dict:\n","  data_dict = {}\n","  k_fold_dir = f\"../data_ready/k_is_{str(k)}/\"\n","  # print (os.path(data_ready_dir))\n","  filenames = []\n","  for (_, _, name) in walk(k_fold_dir): \n","    filenames.extend(name)\n","\n","  for fname in filenames:\n","    dataframe = pd.read_csv(k_fold_dir+fname).sample(frac=1)\n","    dict_key = fname.split(\".csv\")[0]\n","    data_dict.update({dict_key : dataframe})\n","\n","  return data_dict"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### output file genertic fuction ####"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def predictions_to_csv(test_text: list, test_class: list, predictions: list, k: int, train_filename: str, pred_output_dir: str):\n","  # output predictions to csv files.\n","  output_df = pd.DataFrame()\n","  output_df[\"text\"] = test_text\n","  output_df[\"class\"] = test_class\n","  # add new predictions as a 3rd column\n","  # dataframe has these columns (test, class, prediction).\n","  output_df[\"predicted\"] = predictions \n","\n","  makedirs(f\"../predictions/k_is_{k}/{pred_output_dir}/\", exist_ok=True)\n","  output_df.to_csv(f\"../predictions/k_is_{k}/{pred_output_dir}/{train_filename}\", index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Baseline test function  \n","this is called once for every train/test pair\n","\n","a note on the train files,  \n","train2.csv contains 8 train data because it contains...\n","- (one english inclusive\n","- one english exclusive\n","- one french inclusive\n","- one french exclusive) * 2 = 8  \n","  \n","this information does not affect anything in this function, it is just good to know.\n","\n","using these extremely small datasets shows the power of fewshot with setfit.  \n","For the fewshot i have done, we get 90%+ with this small data.  \n","hopefully these baselines predict very bad."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def do_baseline_tests(test_text: list, test_class: list, train_text: list, train_class: list, k: int, train_filename: str, Tfidf: TfidfVectorizer, sentnece_transformer: SentenceTransformer):\n","  ########################## begin basline tests ##########################\n","  \"\"\"\n","    Baseline models here.\n","    test_text, test_class, train_text, train_class are lists\n","    classes are balanced.\n","  \"\"\"\n","  ############################\n","  ####  TF-IDF encodings  ####\n","  train_tfidf = Tfidf.fit_transform(train_text).toarray()\n","  test_tfidf = Tfidf.transform(test_text).toarray()\n","  ############################\n","\n","  ############################\n","  ####   BERT encodings   ####\n","  train_encodings = sentnece_transformer.encode(train_text)\n","  test_encodings = sentnece_transformer.encode(test_text)\n","  ############################\n","\n","  ### Gaussian NaiveBayes ###\n","  NaiveBayes = GaussianNB()\n","  ## TF-IDF ##\n","  NaiveBayes.fit(train_tfidf,train_class)\n","  pred_NB_TFidf = NaiveBayes.predict(test_tfidf)\n","  predictions_to_csv(test_text, test_class, pred_NB_TFidf, k, train_filename, \"TFidf/GaussianNB\")\n","  ## BERT ##\n","  NaiveBayes.fit(train_encodings,train_class)\n","  pred_NB_Bert = NaiveBayes.predict(test_encodings)\n","  predictions_to_csv(test_text, test_class, pred_NB_Bert, k, train_filename, \"Bert/GaussianNB\")\n","\n","  ### Linear SVC ###\n","  LinearSVM = LinearSVC(C=1.0)\n","  ## TF-IDF ##\n","  LinearSVM.fit(train_tfidf, train_class)\n","  pred_SVM_TFidf = LinearSVM.predict(test_tfidf)\n","  predictions_to_csv(test_text, test_class, pred_SVM_TFidf, k, train_filename, \"TFidf/LinearSVM\")\n","  ## BERT ##\n","  LinearSVM.fit(train_encodings, train_class)\n","  pred_SVM_Bert = LinearSVM.predict(test_encodings)\n","  predictions_to_csv(test_text, test_class, pred_SVM_Bert, k, train_filename, \"Bert/LinearSVM\")\n","\n","  ### Logistic Regression ###\n","  lr = LogisticRegression(C=11,class_weight = 'balanced')\n","  ## TF-IDF ##\n","  lr.fit(train_tfidf,train_class)\n","  pred_LR_TFidf = lr.predict(test_tfidf)\n","  predictions_to_csv(test_text, test_class, pred_LR_TFidf, k, train_filename, \"TFidf/LogisticRegression\")\n","  ## BERT ##\n","  lr.fit(train_encodings,train_class)\n","  pred_LR_Bert = lr.predict(test_encodings)\n","  predictions_to_csv(test_text, test_class, pred_LR_Bert, k, train_filename, \"Bert/LogisticRegression\")\n","\n","  ### Random Forest ###\n","\n","  ## TF-IDF ##\n","  sc_X = StandardScaler(with_mean=False)\n","  X_train_RF_TFidf = sc_X.fit_transform(train_tfidf)\n","  X_test_RF_TFidf = sc_X.transform(test_tfidf)\n","\n","  classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n","  classifier.fit(X_train_RF_TFidf,train_class)\n","  pred_RF_TFidf = classifier.predict(X_test_RF_TFidf)\n","  predictions_to_csv(test_text, test_class, pred_RF_TFidf, k, train_filename, \"TFidf/RandomForest\")\n","\n","  ## BERT ##\n","  X_train_RF_Bert = sc_X.fit_transform(train_encodings)\n","  X_test_RF_Bert = sc_X.transform(test_encodings)\n","\n","  classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n","  classifier.fit(X_train_RF_Bert,train_class)\n","  pred_RF_Bert = classifier.predict(X_test_RF_Bert)\n","  predictions_to_csv(test_text, test_class, pred_RF_Bert, k, train_filename, \"Bert/RandomForest\")\n","\n","  ### DecisionTree ###\n","  clf = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n","  ## TF-IDF ##\n","  clf = clf.fit(train_tfidf, train_class)\n","  Pred_DT_TFidf = clf.predict(test_tfidf)\n","  predictions_to_csv(test_text, test_class, Pred_DT_TFidf, k, train_filename, \"TFidf/DecisionTree\")\n","  ## BERT ##\n","  clf = clf.fit(train_encodings, train_class)\n","  Pred_DT_Bert = clf.predict(test_encodings)\n","  predictions_to_csv(test_text, test_class, Pred_DT_Bert, k, train_filename, \"Bert/DecisionTree\")\n","\n","  ### XGboost ###\n","  classifier = SGDClassifier()\n","  ## TF-IDF ##\n","  classifier.fit(train_tfidf , np.ravel(train_class))\n","  pred_XG_TFidf = classifier.predict(test_tfidf)\n","  predictions_to_csv(test_text, test_class, pred_XG_TFidf, k, train_filename, \"TFidf/XGboost\")\n","  ## BERT ##\n","  classifier.fit(train_encodings , np.ravel(train_class))\n","  pred_XG_Bert = classifier.predict(test_encodings)\n","  predictions_to_csv(test_text, test_class, pred_XG_Bert, k, train_filename, \"Bert/XGboost\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### driver function for all baseline tests."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"CUDA error: CUBLAS_STATUS_NOT_SUPPORTED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb Cell 9\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_text \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_dict\u001b[39m.\u001b[39mget(key)[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m# train data X\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m train_class \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_dict\u001b[39m.\u001b[39mget(key)[\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m# train data Y\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m do_baseline_tests(test_text, test_class, train_text, train_class, k ,key, Tfidf, sentence_tranformer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbaselines done for \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m in fold \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[1;32m/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_tfidf \u001b[39m=\u001b[39m Tfidf\u001b[39m.\u001b[39mtransform(test_text)\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m############################\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# #### fastText encodings ####\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# fasttext.util.download_model('en', if_exists='ignore')  # english\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m############################\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m####   BERT encodings   ####\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_encodings \u001b[39m=\u001b[39m sentnece_transformer\u001b[39m.\u001b[39;49mencode(train_text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m test_encodings \u001b[39m=\u001b[39m sentnece_transformer\u001b[39m.\u001b[39mencode(test_text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m############################\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/blake/4thyear/Racially-Exclusive-Speech-Detection/final/classifications/baselines.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m### Gaussian NaiveBayes ###\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:579\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    578\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    580\u001b[0m     x\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    581\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    582\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    583\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    584\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    585\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    586\u001b[0m )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:354\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    352\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_state,)\n\u001b[0;32m--> 354\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    355\u001b[0m     x\u001b[39m=\u001b[39;49mhidden_state, attn_mask\u001b[39m=\u001b[39;49mattn_mask, head_mask\u001b[39m=\u001b[39;49mhead_mask[i], output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    357\u001b[0m hidden_state \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:289\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m sa_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    290\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    291\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    292\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    293\u001b[0m     mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    294\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    295\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    296\u001b[0m )\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    298\u001b[0m     sa_output, sa_weights \u001b[39m=\u001b[39m sa_output  \u001b[39m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:214\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    211\u001b[0m v \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_lin(value))  \u001b[39m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    213\u001b[0m q \u001b[39m=\u001b[39m q \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(dim_per_head)  \u001b[39m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(q, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m))  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    215\u001b[0m mask \u001b[39m=\u001b[39m (mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mview(mask_reshp)\u001b[39m.\u001b[39mexpand_as(scores)  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    216\u001b[0m scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mmasked_fill(\n\u001b[1;32m    217\u001b[0m     mask, torch\u001b[39m.\u001b[39mtensor(torch\u001b[39m.\u001b[39mfinfo(scores\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mmin)\n\u001b[1;32m    218\u001b[0m )  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_SUPPORTED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`"]}],"source":["for k in range(0,3): # this will run for every fold we have data for.\n","  data_dict = read_data_for_fold(k)\n","  # print(data_dict.keys())\n","  # for value in data_dict.values():\n","  #   print(value.shape)\n","  test = data_dict.pop(\"test\")\n","  test_text = list(test[\"text\"]) # test data X\n","  test_class = list(test[\"class\"]) # test data Y\n","\n","  Tfidf = TfidfVectorizer(max_features=15000)\n","  sentence_tranformer = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n","\n","  for key in data_dict.keys():\n","    train_text = list(data_dict.get(key)[\"text\"]) # train data X\n","    train_class = list(data_dict.get(key)[\"class\"]) # train data Y\n","    do_baseline_tests(test_text, test_class, train_text, train_class, k ,key, Tfidf, sentence_tranformer)\n","    print(f\"baselines done for {key} in fold {k}\")"]}],"metadata":{"kernelspec":{"display_name":"fyp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"9a087ff6df60b7b11c8f40c254358573ffeaae9884c78b2d4011057590ac9004"}}},"nbformat":4,"nbformat_minor":2}
