{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/blake/venvs/fyp/lib/python3.8/site-packages (4.26.0)\n",
      "Requirement already satisfied: filelock in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/__main__.py\", line 16, in <module>\n",
      "    from pip._internal.cli.main import main as _main  # isort:skip # noqa\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/_internal/cli/autocompletion.py\", line 9, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/_internal/cli/main_parser.py\", line 7, in <module>\n",
      "    from pip._internal.cli import cmdoptions\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/_internal/cli/cmdoptions.py\", line 24, in <module>\n",
      "    from pip._internal.exceptions import CommandError\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/_internal/exceptions.py\", line 10, in <module>\n",
      "    from pip._vendor.six import iteritems\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/_vendor/__init__.py\", line 79, in <module>\n",
      "    vendored(\"pkg_resources\")\n",
      "  File \"/home/blake/venvs/fyp/lib/python3.8/site-packages/pip/_vendor/__init__.py\", line 36, in vendored\n",
      "    __import__(modulename, globals(), locals(), level=0)\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _load_backward_compatible\n",
      "  File \"<frozen zipimport>\", line 259, in load_module\n",
      "  File \"/usr/share/python-wheels/pkg_resources-0.0.0-py2.py3-none-any.whl/pkg_resources/__init__.py\", line 84, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _load_backward_compatible\n",
      "  File \"<frozen zipimport>\", line 259, in load_module\n",
      "  File \"/usr/share/python-wheels/pkg_resources-0.0.0-py2.py3-none-any.whl/pkg_resources/_vendor/packaging/requirements.py\", line 9, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _load_backward_compatible\n",
      "  File \"/usr/share/python-wheels/pkg_resources-0.0.0-py2.py3-none-any.whl/pkg_resources/extern/__init__.py\", line 43, in load_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _load_backward_compatible\n",
      "  File \"<frozen zipimport>\", line 241, in load_module\n",
      "  File \"<frozen zipimport>\", line 713, in _get_module_code\n",
      "  File \"<frozen zipimport>\", line 647, in _compile_source\n",
      "KeyboardInterrupt\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyarrow in /home/blake/venvs/fyp/lib/python3.8/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/blake/venvs/fyp/lib/python3.8/site-packages (from pyarrow) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install setfit\n",
    "%pip install pyarrow\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from os import walk, makedirs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### output file genertic fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_csv(test_text: list, test_class: list, predictions: list, k: int, train_filename: str, num_epoch: int, pred_output_dir: str):\n",
    "  # output predictions to csv files.\n",
    "  output_df = pd.DataFrame()\n",
    "  output_df[\"text\"] = test_text\n",
    "  output_df[\"class\"] = test_class\n",
    "  # add new predictions as a 3rd column\n",
    "  # dataframe has these columns (test, class, prediction).\n",
    "  output_df[\"predicted\"] = predictions \n",
    "\n",
    "  makedirs(f\"../predictions/k_is_{k}/{pred_output_dir}/\", exist_ok=True)\n",
    "  output_df.to_csv(f\"../predictions/k_is_{k}/{pred_output_dir}/{num_epoch}epoch_{train_filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setfit_on_pretrained(test_text: list, test_class: list, train_text: list, train_class: list,\n",
    "                        train_filename: str, k: int, pretrainied_model_string: str, num_epoch:int) -> None:\n",
    "\n",
    "  train_dataset = datasets.Dataset(pa.Table.from_arrays([train_text, train_class], [\"text\",\"class\"]))\n",
    "\n",
    "  model = SetFitModel.from_pretrained(pretrainied_model_string)\n",
    "\n",
    "  # total training data for each network is 320 per epoch\n",
    "  # because training data size fluctuates, we need to generate equal number for setfit pairs to have fair training.\n",
    "  # this way we are effectively testing if diversity in data matters.\n",
    "  # for traintest2 : 8*x*2 = 320 , 160/8 = x  <- same math\n",
    "  num_iter = round(160/len(train_text))\n",
    "\n",
    "  trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    metric=\"accuracy\",\n",
    "    batch_size=16,\n",
    "    num_iterations=num_iter, # The number of text pairs to generate for contrastive learning\n",
    "    num_epochs=num_epoch, # The number of epochs to use for contrastive learning\n",
    "    column_mapping={\"text\": \"text\", \"class\": \"label\"} # Map dataset columns to text/label expected by trainer\n",
    "  )\n",
    "  # train network\n",
    "  trainer.train()\n",
    "  # predict with network\n",
    "  predictions = trainer.model.predict(test_text)\n",
    "\n",
    "  # output filename\n",
    "  modelnamesplit = pretrainied_model_string.split('/')\n",
    "  modelname = modelnamesplit[len(modelnamesplit)-1]\n",
    "\n",
    "  predictions_to_csv(test_text,\n",
    "                    test_class,\n",
    "                    predictions,\n",
    "                    k,\n",
    "                    train_filename,\n",
    "                    num_epoch,\n",
    "                    modelname\n",
    "                    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### function to read all data in from data_ready/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_for_fold(k: int) -> dict:\n",
    "  data_dict = {}\n",
    "  k_fold_dir = f\"../data_ready/k_is_{str(k)}/\"\n",
    "  # print (os.path(data_ready_dir))\n",
    "  filenames = []\n",
    "  for (_, _, name) in walk(k_fold_dir): \n",
    "    filenames.extend(name)\n",
    "\n",
    "  for fname in filenames:\n",
    "    dataframe = pd.read_csv(k_fold_dir+fname).sample(frac=1)\n",
    "    dict_key = fname.split(\".csv\")[0]\n",
    "    data_dict.update({dict_key : dataframe})\n",
    "\n",
    "  return data_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ran tests:\n",
    "  morit/french_xlm_xnli\n",
    "  Hate-speech-CNERG/dehatebert-mono-french\n",
    "\"\"\"\n",
    "\n",
    "#ovverride to do one at a time.\n",
    "modelnames = [\"\"]\n",
    "\n",
    "for modelname in modelnames:\n",
    "  for k in range(0,3): # this will run for every fold we have data for.\n",
    "    data_dict = read_data_for_fold(k)\n",
    "    test = data_dict.pop(\"test\")\n",
    "    test_text = list(test[\"text\"]) # test data X\n",
    "    test_class = list(test[\"class\"]) # test data Y\n",
    "    for filename in data_dict.keys():\n",
    "      train_text = list(data_dict.get(filename)[\"text\"]) # train data X\n",
    "      train_class = list(data_dict.get(filename)[\"class\"]) # train data Y\n",
    "      for epochs in range(1,3):\n",
    "        setfit_on_pretrained(\n",
    "          test_text,\n",
    "          test_class,\n",
    "          train_text,\n",
    "          train_class,\n",
    "          filename,\n",
    "          k,\n",
    "          modelname,\n",
    "          epochs\n",
    "          # 20 #8x20x2 = 320\n",
    "        )\n",
    "      print(f\"fewshot done for {filename} in fold {k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a087ff6df60b7b11c8f40c254358573ffeaae9884c78b2d4011057590ac9004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
